[{"content":" Data are like humans. You have to spend time with them to understand them.\n ","href":"/","title":"Home"},{"content":"","href":"/post/","title":"Posts"},{"content":" Here is a paragraph. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nHeading 2 Another one. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\nHeading 3 Yet another, but centered! Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n Heading 4  First item Second item  Nested unordered item  Third item  Nested ordered item 1 Nested ordered item 2   Heading 5 Where are the quotes!!!\n Simplify, then add lightness.\n— Colin Chapman\n Now, time for some links!\n GoHugo  Hugo Themes   Heading 6 Inline code: echo \u0026quot;What is the meaning of life?\u0026quot;. Who knows?\n// Codeblock  var meaningOfLife = 42; console.log(\u0026#39;The meaning of life is: \u0026#39;, meaningOfLife);  Who wants some table?\n   Minimo Caption More Caption     Cool What? Now, wut?!    Ah, enough for today, eh?\n","href":"/typography/","title":"Typography"},{"content":"This site, deepLearner, is not about Deep Learning as we understand in the field of Data Science. Rather, the purpose here is to express deep learning in the sense of learning something at the core. In other words, learning and taking it from shallow to a deeper level of understanding.\nWe are all learners. Some of us are deep learner. That’s deepLearnR.\nOf course learning the technologies, i.e., data science, in particular, will be a major focus of our articles. Most importantly, statistical thinking will be at the core.\nIt is worth mentioning that many aspects of data science overlap with what has been there for over hundred years. Statisticians played and continue to play a central role in knowledge discovery from data. However, a new era has emerged with a massive amount of data from almost every aspect of our lives. Thus, it has opened many new possibilities where the use of deep learning techniques has become essential.\nIn short, problems that statisticians solve are, by and large, different than the problems that artificial intelligence community solves.\nBoth have their places and relevance in the present time.\n","href":"/about/","title":"About"},{"content":" Power BI is a great tool for creating interactive statistical tables with the aid of R. When using R as a data connector, you can use a single R script to have multiple data frames loaded into Power BI.\nOften, as we are developing the report, you will add or remove tables in the single R script. It is convenient to have all the codes in a single table since most of the data frames are derived from the main data set.\nwe harness the power of R.\nThe problem LInk\nSolution Conclusion ","href":"/post/power-bi-single-r-script-for-multiple-data-sets-tables/","title":"Power BI single R script for multiple data sets / tables"},{"content":" Microsoft Power BI Desktop version nicely integrates with R. R is an open source software for statistical computing and graphics. R has become popular among the data scientists because of its powerful data analytics and visualization capabilities. Power BI is Microsoft\u0026rsquo;s flagship BI tool for creating dashboards and interactive reports. With R as a backend engine for Power BI Desktop, you can do many cool things, which can be categorized into three broad applications\u0026ndash;\n using R to import data into Power BI, using R to query existing data in Power BI, and creating visuals with R script  In this article, I have demonstrated how to use R with Power BI to perform these applications.\nApplication 1: Using R to import data sets into Power BI Power BI can import data from a variety of sources. For a complete list, please see here.\nImporting Excel .xlsx or .csv files into Power BI is perhaps the most common usage. However, I\u0026rsquo;ve personally found it to be problematic. In particular, if your source data is continuously updating including addition or removal of columns, then the changes do not get updated when you simply refresh the data sources from Power BI Desktop. This is a problematic when you are developing your interactive report and also when the dashboard is in production.\nA more robust solution of importing data is to use R script. This is known as Running R scripts in Power BI Desktop.\nPreparing the R script in R Studio This is the stage you would write your R script to load your data. I use R studio for that. RStudio is a popular Integrated Development Environment (IDE) for R. If you are not familiar with RStudio, you can use the default R editor or wherever you write your R codes. You do not need any special preparation. Just use the editor to test your code before using in Power BI.\nI am going to create a smiple data set with two columns using the R codes below. This data is being created for demonstration purposes only so that you can reproduce it when you are learning.\n# Sample data frame object df \u0026lt;- data.frame( x= rnorm(100), y= rnorm(100) + rnorm(100) ) head(df) This code creates an R data.frame and saves in an object df. This will be the name of the data when you import into Power BI. You can give the data object any valid R-name you want.\nThe above code also shows head(df), but Power BI only imports data.frame. In this case, it will only import the df object and ignore the rest. So you don\u0026rsquo;t have to worry about other codes in the script. Just make sure all codes run without error and without any dependencies.\nRun your R script and import data In Power BI Desktop, the R Script data connector is found in Get Data menu. Click on Get Data \u0026gt; More\u0026hellip;, then select Other \u0026gt; R script as shown in the following image:\nNotice that at the bottom of the above image, the your R installation path is displayed. If you have multiple installation of R, then you would need to go to Options and Settings \u0026gt; Options \u0026gt; R scripting and then setting the location of the R installation you would like to use.\nError message After you enter the R script and hit OK, you might see a connection error message as follows:\nIn that case, you need to click on Retry and that will take to you the following message to enable native database query. Click on Run. If you want to know more about risk involved with this option please see the official documentation\nAfter that, it should run without any issue and you should see a window like the following:\nLoading the data Once you are at this stage, you select the data frame created with the R script (in this case df), and then click Load (or Edit if you want). This should load the data in Power BI. You can verify that in the Fields pane that the df has indeeded loaded as shown in the folowing:\nNow that you\u0026rsquo;ve successfully imported the data using R script, you can use the variables the typical way you would work within Power BI Desktop. If you want to add or edit any new column/variables or anything with the data using the R script, you would need to update the R script and load the data as usual.\nWhen you edit the R script, you should not see any error/warning messages because you\u0026rsquo;ve already made those exceptions.\nUpdating the R script It is obvious that you would be updating the R script since that was the whole purpose of importing the data via R script. You continue to edit the script in RStudio and when you are ready to update the code within Power BI, you need to go to Edit Queries option.\nSimply right-click on the data under the FIELDS pane, and select Edit query. This should open the Power Query Editor and you can click on the gear icon ([1] in figure) as shown below:\nClicking that gear icon should open the R script editor where you can replace the existing code with the updated code. When you are ready, click OK, and then click Close \u0026amp; Apply ([2] in the figure) in the Power Query Editor to apply the changes.\nApplication 2: Using R to query existing data in Power BI This application is useful for manipulating an already imported dataset. That is, data have been imported into Power BI Desktop, and now you want to do some cleaning or perform transformations. Essentially, you could do all of those while importing the data (Application 1). Interested readers may find the detailed document available from Microsoft Power BI on using R in Query Editor. I am giving an example to demonstrate how it works.\nExample to demonstrate re-coding Suppose we\u0026rsquo;ve imported a data set with missing vlaues and unusually large numbers in some of the fields. We want to perform some cleaning. Of course this is a fictitious example just to demonstrate the idea.\nWe use the R code to generate the data\ndf \u0026lt;- data.frame( name = c(\u0026#34;John\u0026#34;, \u0026#34;Arif\u0026#34;,\u0026#34;Samira\u0026#34;), sex = c(1, 1, 2), gpa = c(4, 3.9, 3.95) ) We will import this data using the R (discussed in Application 1). Once loaded, we will then do some transformations. To keep it simple, we will just recode the sex variable to indicate Male for 1 and Female for 2. For that, we use the following codes which we would enter in the R script:\n# \u0026#39;dataset\u0026#39; holds the input data for this script library(dplyr) newcalc \u0026lt;- dataset %\u0026gt;% mutate( sex = ifelse(sex == 1, \u0026#34;Male\u0026#34;, \u0026#34;Female\u0026#34;) ) Entering R script to transform data  Click on the Edit Queries button in Power BI Desktop to open the query editor. Select the appropriate query under the Queries[] menu on the left of the screen. Click on the Transform menu above the ribbon. You will see the Run R Script button with the R icon. Click that.  Enter the R code that will be used to do the transformation. The screen would look like the following:\nClick OK. If you see any permission error or message like that, follow the prompts and allow the R codes to execute. Once you successfully pass all the prompts (if any), you will get the screen that looks like this\u0026ndash;\nMake sure to click on the Table field shown with the arrow in the figure. That will create the new step named newcalc and the table as shown in figure below.\nNow you click on the Home menu and hit the icon that says Close \u0026amp; Apply as shown in the figure below.\nNow the sex variable in the table should be a character variable with values Male and Female instead of 1s and 2s.\nAnd you are done!\nApplication 3: Creating visuals with R script One of the best applications of R with Power BI is that you can harness the power of R to create high quality graphs and display them within your report/dashboard in Power BI. All the filters/slicers will work as usual and the graphs will the dynamically updated when you slice your data.\nYou can bring R visual into Power BI in two ways\u0026ndash;\n Importing an R visual from Microsoft AppSource You can wirte you own code to create the visuals.  In this article, I\u0026rsquo;ve demonstrated how to use your own code to create visuals with R and display them in Power BI.\nExample with mtcars data This assumes that we already have a dataset in Power BI. For the sake of reproducibility of this example, I will create the data. This time, I will just load a car data set called mtcars available within R.\nSimply follow the steps in Application 1, using the code entered in the R script window:\ndf \u0026lt;- mtcars This loads the data in Power BI as shown in the figure below.\nNow, we would like to create a boxplot of gas mileage (miles per gallon) by cylinder type. We call the\nTo creat a R visual, click on the R icon from VISUALIZATIONS pane as seen in the above image (the icon is pointed with a red arrow).This should create a placeholder for a visual in the canvas and an R script editor will show up at the bottom of the screen.\nSelect the variables you want to use for the visual. In our case, we would need cyl and mpg. Once you select them, the R script editor will update with some basic codes (uneditable).\nNow you are ready to enter the following code in the area where it says \u0026ldquo;Type or paste your R-script code here\u0026rdquo;. Enter the code below:\nboxplot(mpg ~ cyl, data = dataset, xlab = \u0026#34;Number of Cylinders\u0026#34;, ylab = \u0026#34;Miles Per Gallon\u0026#34;, main = \u0026#34;Gas Mileage\u0026#34;, notch = FALSE, varwidth = TRUE, col = c(\u0026#34;blue\u0026#34;,\u0026#34;green\u0026#34;,\u0026#34;red\u0026#34;), names = c(\u0026#34;High\u0026#34;,\u0026#34;Medium\u0026#34;,\u0026#34;Low\u0026#34;) ) Then click on the little play button near the top of the script-editor to display the plot on canvas.\nAnd it\u0026rsquo;s that easy.\nHope this tutorial was useful for you. If you have any question or have some tips, please leave them as a comment.\nI appreciate if you share this via social media. Thank you for reading.\n","href":"/post/integrating-r-with-powerbi-desktop/","title":"Integrating R with Power BI"},{"content":" Github needs no introduction. If you are unfamiliar with git, its a version control system for tracking changes in computer (programming) codes. \u0026ldquo;GitHub Inc. is a web-based hosting service for version control using Git. It is mostly used for computer code. It offers all of the distributed version control and source code management functionality of Git as well as adding its own features.\u0026rdquo;1\nCopying a remote repository to local To bring a remote repository to your local host (computer where you are working), use the git clone command.\ngit clone https://github.com/username/repository_name.git Publishing the changes After you update your code or add or remove anything from the repository, you want to publish to the remote repository.\nPublishing the changes is called push in git jargon. For that you need to write the following codes.\ngit add -A git commit -m \u0026#34;Message/notes of what the changes are\u0026#34; This will update the local repository. Now you want to publish the changes using the following command\ngit push You may want to be more specific about which remote to update. The default remote is origin. The command would be\ngit push origin master Syncing a remote repository on two local hosts Sometime I work on two or three different computers for the same remote project. So keeyping the repositories in sync is essential. I want my codes to be synced accross multiple computers.\nFor that I follow these simple steps.\n- Pull the remote repository in your new workstation - Make changes to your code - Push (publish) the updates  The key is to pull and update the local repository assuming the remote has the latest updates.\ngit pull git add -A git comit -m \u0026#34;Update message\u0026#34; git push origin master Last updated: 2018-07-30\n Wikipedia [return]   ","href":"/post/frequently-used-git-commands/","title":"Frequently used git commands"},{"content":"Today is 7/26\nThis is test post to check if Python code works\nlibrary(reticulate) ## Warning: package \u0026#39;reticulate\u0026#39; was built under R version 3.4.4 import numpy as np x = [1, 2, 3] print(x) ## [1, 2, 3] y = np.mean(x) \\(\\bar{x}\\) is the average, which is defined as \\[ \\bar{x} = \\frac{\\sum x}{n} \\]\nSo what is the aveage of y? It is 2.\nx = c(1:5) The value of x is R session is 1, 2, 3, 4, 5.\nMore text is to be added.\nR Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 ```\n Testing LaTeX This is an inline test for math content in markdown \\(\\bar{x}\\). And this is a mathe block, defining the average– \\[ \\bar{x} = \\frac{\\sum x}{n} \\]\nAnd some more complicated formula\n\\[ y = x_1 \\beta_1 + x_2 \\beta_2 + \\epsilon \\] is the multiple linear regression model with two covariates \\(x_1\\) and \\(x_2\\).\nWhen \\\\( a \\ne 0 \\\\), there are two solutions to $$ ax^2 + bx + c = 0 $$ and they are: \\\\[ x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a} \\\\]  ","href":"/post/python-using-rstudio-ide/","title":"Python using RStudio IDE"},{"content":" A lot of times interested folks contact me with a question like this: ‘I want to be a data scientist; can you help?’\nWell, I wish I could. The reality is, I won’t be able to unless I really understand what you want and why you want it.\nFirstly because guiding someone is next to impossible in this time and era when everything is so convoluted. People come to learn with preconceived ideas and notions. I am not saying you have to come with a blank slate, what I am saying is you need to show real motivation. I repeat, you must have a motivation and you must be able to articulate why you are motivated.\nThere is no shortage of tutorials, courses, documents, websites, articles today on how to become a data scientist. Sadly, most of the times there is a business mind lurking behind such documents and campaigns. They will tell you only partial truth. They will tell you that you can become a data scientist in 4 months, or in 6 months, or by completing a boot camp and so on and so forth.\nIn my opinion, if you already have the background of a typical data scientist (have worked with data, have knowledge of scientific process, programming skills in R, Python, SAS, or any relevant language), then yes, you can acquire the knowledge and become familiar with the tools that data science utilizes within a short period of time.\nOn the other hand, if you are a complete novice, you will not only be deceived by these campaigns but also become frustrated quickly. This is because you were drawn to something for which you were not prepared for. And you did not anticipate the challenges you would face to become a data scientist.\nNow let’s come to the main point.\nWhy do you want to become one Ask yourself the “why” question and give an honest answer. What is your response?\nIt is perfectly okay to say that you want to be a data scientist because the market is hot.\nBut the best approach would be to write a few points on a piece of paper as to why do you want to become a data scientist.\n Point 1 Point 2 Point 3 Point 4  You could list that you are passionate about working with data; you want to make an impact by helping the management or team leaders making the right decision based on data, or you just enjoy solving other’s problems with data.\nWhatever may be your reasons, it is important to list them down. Listening makes you look at it by yourself. That helps you to assess whether this is really something you want to do.\nMotivation is the key.\nKnow what is data science and who are data scientists Before you jump into this field, do some research about the field. Google it, find some blogs to follow, read some whitepapers from reputed analytic organizations and software companies such as SAS, IBM, Google, Microsoft and many others. Spend some time reading. Not just skimming through; actual reading. To me, reading is the best way to broaden knowledge. In this era of YouTube and video lectures, I still find reading somewhat superior, especially for beginners. Once you have acquired a general understanding of the field, listening to lectures or watching short video clips would boost your knowledge quickly.\nWhat do data scientists do I will write briefly. I am working work on a separate article on it.\n Data scientists solve problems with the help of data. That’s what they do.\n On paper, Data Scientists do so many things that someone with a title of data scientist in one industry cannot possibly list what another data scientist might be doing in a different industry. That is to give you an idea of how variable the type of works data scientists is involved with.\nSimply put, data scientists work with data to bring actionable insight that helps to solve a problem. If the data scientist is working in a financial organization, the problems would be related to, say, banking industry, the stock market, etc. If the data scientist works in healthcare, the problem would be related to healthcare service provider such as hospitals, health units.\nData scientists do not necessarily get involved with building the data architecture such as data warehousing or setting up or maintaining cloud infrastructure for an organization. Those who work in this type of work are called ‘Data Engineers’. You may want to read a little more about this in my earlier post (in Bengali).\nLet me clarify one thing–data scientists do not necessarily design the databases. It is the data engineers who do that. Data scientists analyze the data to drive business whereas data engineers develop and maintain the architecture that stores data. Data scientists or statisticians do not build or maintain databases in most of the cases. However, there is often a need to create smaller databases for a specific purpose or a project. A data scientist may need to design, develop and maintain project-specific databases, which are largely different from enterprise-level data warehouse.\nMost large organizations have their separate team of engineers who develop and maintain the data-science platforms (DBs, Hadoop, etc.).\nHow to become a data scientist Everyone wants to be a data scientist but only some will be successful. The reason is in part, your preparation, in part your effort. If you are not from a quantitative background with some math, and computer programming experience, I would say it would be a daunting task for you to learn what it takes to be a data scientist. I am completely being honest.\nAt some point in time, you are going to read and write computer programs.\nIf you’ve never written a computer program, I am not sure how long it will take for you to pick up a language. But I personally feel that it takes at least 6 months to get some basics of any programming language. Another year or so to know a bit more. If you engage yourself full time to learn a language, you might be able to write simple programs and carry out simple data science tasks within 4-6 months.\nTwo approaches to be a Data Scientist Learn the tools to become data scientist, or Find the problems you want to solve, and then learn what it takes to solve them\nThe first approach is the typical approach and I call it bottom-up approach. I will not discuss the first approach because it has been the mainstream approach thus far. This has brought so many discussions, lot of training offerings, online courses, articles in the media, blogs, and vlogs, and much more.\nI will focus on the second approach to becoming a data scientist. I call it top-down approach.\nFind problems that you want to solve This is perhaps the easiest way to find out if you really want to be a data scientist. If so, keep reading.\nI call this approach a top-down approach, you first find a problem and then solve it.\nAs I wrote earlier in this article, data scientists solve problems with the help of data. In other words, they have a problem to solve in front of them and they would provide a solution using data.\nNow this may sound like, well, problem is there, the data is there, so what’s the big deal?\nIt’s not a big deal, but its a huge deal.\nHaving the data is only one step to solving the problem. What if you do not have the data in the right form, or you do not have the data in the first place. If you have the data, it often takes 80% of your time to prepare it for your analysis.\nIf you do not have the data, then you first need to get the data in the first place.\nWhere do I find problem? Well, problems are everywhere, you just have to look around.\nI am going to give you some ideas which should give you enough clues to find a problem on your own and discover what it takes to solve those problems. Here goes the list with brief descriptions.\nProblem 1: Building a list of most important news of the day\nThis may sound like an unattractive problem. But think about how you might want to use the information. First, you need to think about a focus area. If you are interested in politics, the possibilities are endless. If you build a list exclusively on “North Korea”, you would find at the end of the year how the things unfolded and you can present the information on a timescale. The importance of such a list is to be able to find temporal relationship between different events which may affect some other event/outcome of interest.\nYou might be aware that news or sometimes a tweet from an influential person can affect the stock price of a particular company in the US stock market. But this could be useful beyond US market. You will find many potential use cases if you think a bit deep.\nProblem 2: Tracking accident statistics\nThis problem is particularly suitable for resource-limited countries where government record keeping is inadequate. Every day newspapers report accidental deaths due to road crashes. You could select one or two major newspapers and scan their pages to retrieve news about road accidents. This could be done as part of a research project at your institution where you pursue a Bachelors or Masters degree.\nProblem 3: Calculating impact of faculty research\nThis is something you can do for your department, or institution or country. Start with your department first where you have only a handful of faculties who are presumably doing some kind of research and publishing their findings in journals. Think of developing an automated system that would find articles (in Google Scholar, for example) and calculate impacts (from the journal impact factors). You can present the results by department, by type of research, or by institution.\nProblem 4: Build an economic performance dashboard\nYou can use Google’s Data Studio to build a dashboard of economic performance of your country on some key performance metrics. The data could be found on the central bank’s website or government data repositories. For Bangladesh, many economic data sets are available online free of charge. Just visit https://www.bb.org.bd/econdata/ and find your data there.\nConclusion In conclusion, you can take the easier route to be a data scientist. In this route, you first need to find a problem and you will point your learning path towards solving that problem. The path is not smooth. But you can always ask questions to someone who knows or someone more experienced. It is a good practice to find someone who would be your mentor and will guide you through your learning path. Since you are learning on your own, you have to take the responsibility on your own. If you do not want to learn, nobody is going to push. If you are really interested and motivated, I hope this article has given you some direction.\nHappy learning.\n","href":"/post/to-the-aspiring-data-scientists/","title":"To the Aspiring Data Scientists"},{"content":" If you are exploring the hot field of Data Science today, you probably know by now that there is no unique way to define data science. Everyone’s perspective comes from their respective backgrounds. Statisticians think they are data scientists while CS folks think they are.\nI would not go into the debate.\nBoth have truth in their arguments as the typical problems they solve are quite different. There are some exceptions where their workflows overlap. Let me provide some thoughts from my perspective.\nI am a statistician by training and I have been in the analytic world for over 15 years. This includes time spent at universities teaching graduate level statistics courses as well as working in the healthcare industry as a data scientist.\nThree types of Statisticians Like many scientific disciplines, statisticians contribute to the science in two different ways.\nFirst, through theoretical contribution to the scientific literature to advance the knowledge. In this type of work, statisticians focus on developing new methods to solve new problems or improving existing methods. In statistical science, any new theoretical development takes several years, sometimes decades, to gain popularity among the mainstream practitioners. Part of it is due to the availability of software packages or lack thereof that the practitioners are most familiar with. And there are some other reasons too.\nSecondly, the works of applied statisticians and applied researchers including epidemiologists who focus on solving problems that need an immediate solution. Most of the time they utilize already developed statistical methods in their workflow. Here’s where most of the overlap happens between the works of applied statisticians and practitioners of statistics.\nHowever, there is no strict boundary between applied and theoretical statisticians. Often, applied statisticians develop new methods to solve an existing problem. Thus, the third kind of statisticians are those who fall somewhere in between theoretical statisticians and applied statisticians.\nTowards Data Science There are, however, some philosophical differences between these two types of statisticians. Theoretical researchers often think they are superior to their counterpart, while the applied folks think they are the ones whose contributions have a real impact. Both are wrong, in my honest opinion.\nCompared to their peers, Applied Statisticians find their views better aligned with the theme of today’s data science. This is perhaps because of the way they were trained during their academic years.\nApplied statisticians are taught and trained to use data to bring insights out of it. They are trained not only to fit a model and know how it works but also to communicate with their customers in non-technical terms. Intuition is all that takes priority over theoretical derivations. As Jo Hardin points 1,\n .. when teaching, for example, the Neyman-Pearson lemma, the intuition behind how we know what we know (and why it matters) is vastly more fundamental for the students’ future research capabilities than the detailed steps of the proof.\n I think it is vital for a student of statistics to learn and think this way to become successful in today’s job market.\nData Scientist Vs Data Engineers The difference between many types of data scientists is often confusing even to the statisticians. Sometimes, data scientists and data engineers are considered equally. In fact, the type of work they do is quite different.\nLet me clarify one thing–data scientists do not necessarily design the databases. It is the data engineers who do that. Data scientists analyze the data to drive business whereas data engineers develop and maintain that architecture. Data scientists or statisticians do not build or maintain databases. Most large organizations have their separate team of engineers who develop and maintain the data-science platforms (DBs, Hadoop, etc.).\nDo the statisticians need to know a bit of database? Yes, a basic understanding is good enough. Most of the time all you will do is pull some tables from different sources and join them to create a working data set. For that, you need to understand basics and you do not have to be a data architect for that. If you are working in a startup company, then you may be required to understand in greater depth, though as they have less manpower.\nHow big of a deal knowing how to efficiently join tables? Not so big. Anyone with a decent knowledge of data and SQL can learn to do it with some reading and practice. But you have to have the mindset of learning in the first place.\nUse of Statistics In my work, I find statistics invaluable although most of the time we do not use many advanced techniques. And this is by far true for most organizations who utilize data for decision-making. High-level analysis such as modeling and machine learning stay at the very top level of the application pyramid. You still need to lay the foundation using basic analysis and visualizations.\nHow media is portraying data science today (such as deep learning and AI) is what perhaps 1% of all the analytics an organization needs. Many large organizations do not hire people for that. They purchase a solution instead as that is more cost-effective. For many problems where deep learning is not applicable, they need analytic people with decent statistical literacy.\nConclusion Data Science as it’s being understood today solves problems that are, for the most part, quite different than the problems that would need statisticians’ help to solve. Being on both sides of the aisle I can see how they complement each other and how they both are relevant.\nLet me know what’s your thoughts are. And please share this article if you find it useful.\nThank you!\n Jo Harding (2017). Expectations and Skills for Undergraduate Students Doing Research in Statistics and Data Science, AMSTAT Newsletter [return]   ","href":"/post/statisticians-in-the-data-science-era/","title":"Statisticians in the Data Science Era"},{"content":"I would like to share a few things with you from recent experience of my transition from academia to industry. Of course I have a lot more experience than a fresh graduate, but something I’ve experienced that many others may benefit from. I believe this will help you to think at least. I’ve written this with the candidates in the US job market in mind.\nFirstly, I would say this– lies, damn lies, statistics, AND one-page resume. I hope you got what I meant. One-page resume never worked for me. Here’s why.\nHiring managers rarely review your resume when you apply for a job. It normally goes through an initial round of review by recruiters. Organizations have partnered with recruiting companies and they do these initial screening. Literally, they will never forward any resume that is one-page. Because one-page resume rarely tells what you have accomplished. It’ll only make you look like hundred or thousand others candidates who have the exact same background and experience (R, SAS, courses, etc.) as you have.\nYou have to literally describe each of your projects and your contributions. You don’t have to describe every details. In fact you should not reveal every details but sufficient enough so that the recruiter understands it and convinced enough to forward your resume.\nThe hiring manager would then scan only your first page, perhaps. So prepare your resume as such.\nSecondly, follow the jobs market closely and regularly. See what the market is looking for. That will put you into the real perspective because as a result of you being well informed, your resume will reflect that.\nThirdly, you need to submit your well detailed resume to several job sites such as CareerBuilder, Indeed, LinkedIn, Monster, Dice etc. I found CareerBuilder and Indeed to be better for stat (industry) jobs. LinkedIn is also good for finding local opportunities.\nPLEASE spend a lot of time to properly submit your resume to these job sites with all possible keywords appropriate for your discipline. It will take about 2 to 3 weeks before the resume is propagated to various recruiters’ networks. Once recruiters find your resume, they will directly call you. Recruiters get a good amount of commission when they are able to forward a good candidate and the company hires the candidate. So they always try to help you. Often they will suggest you to modify your resume to make it suitable for that particular position.\nFourth, have patience. A lot of patience. You have to knock every possible door, and only some doors will open.\nFifth, prepare yourself for the interview. I find Liz Ryan (www.linkedin.com/in/lizryan) to be excellent. You will find her in LinkedIn. Follow her. It’s really really helpful. I wish I would have found her earlier.\n","href":"/post/preparing-for-statistics-jobs-in-the-industry/","title":"Preparing for statistics jobs in the industry"},{"content":" সবকিছুই এখন দ্রুত চলছে — প্রযুক্তির উন্নয়ন হচ্ছে দ্রুত, সামাজিক পরিবর্তন হচ্ছে অনেকটা চোখের সামনেই, বাড়ছে মানুষ, আর সেইসাথে বাড়ছে ডেটা!\nসময়ের প্রয়োজনে গবেষণা এখন হয়ে উঠেছে কোলাবরেটিভ বা সহযোগিতামূলক। এতে সুবিধা অনেক। একসাথে অনেক ফিল্ডের এক্সপার্টরা কাজ করছে যার ফলে প্রোডাক্টিভিটি বেড়েছে। অর্থাৎ অল্প সময়ে দ্রুত প্রোডাক্ট (রিসার্চ পেপার) বের করা সম্ভব হচ্ছে। নব্বইয়ের দশক থেকে শুরু করে তার পরবর্তী সময়কালে কোলাবরেটিভ কাজের সুযোগ ও আগ্রহ দুইই বেড়েছে।\nতরুণ গবেষকদের কোলাবরেটিভ কাজ শুরু করার প্রাথমিক ধাপ হলো রিসার্চ কীভাবে করে সে সম্পর্কে ধারণা থাকা। আমাদের দেশের বিশ্ববিদ্যালয়গুলোতে রিসার্চ মেথডলজি নামে একটি বিষয় পড়ানো হয়। গবেষণা পদ্ধতি জানতে এবং তার ব্যবহারিক রূপ দেখতে এই কোর্সের কোন বিকল্প নেই। কাজ করে করে কাজ শেখা যায় তবে সেটি আরো এফিসিয়েন্ট হয় যদি তাত্ত্বিক জ্ঞান অর্জন করা থাকে। যেটি সম্ভব হয় এরকম কোর্স করার মাধ্যমে।\nপ্রথাগত কোর্স করলেই যে সবাই সবকিছু শিখে নেবে এমনটি নয়। তবে কোন কিছু সম্পর্কে একেবারে অন্ধকারে থাকার চেয়ে কিছুটা জানা ভালো যদি সেই জানাকে পরবর্তীতে জ্ঞান আহরণের প্রাথমিক ধাপ হিসেবে বিবেচনা করা হয় এবং সেরকম প্রচেষ্টা থাকে।\nদু:খজনক হলেও সত্যি যে আমাদের দেশে পড়াশুনা ও গবেষণার জন্য সত্যিকার কোন মোটিভেশন না থাকায় এই কোর্সটিও কাগুজে কোর্সে পরিণত হয়। এরকম কোর্স থেকে শিক্ষার্থীরা সামান্য কিছুই পেয়ে থাকে যেগুলোকে তারা পরবর্তীতে নিজেদের গবেষণায় কাজে লাগাতে পারে। এর কারণ বহুবিদ। অন্যতম কারণটি হলো শিক্ষার সাথে ব্যবহারিক কাজের কোনো সম্পর্ক না থাকা।\nএই সমস্যার উত্তরণের একটি পথ আছে যেটি হলো গবেষণায় নেমে পড়া। বাংলাদেশের তরুণ শিক্ষার্থীরা অনেকেই গবেষণা করতে চায় কিন্তু কীভাবে করবে সেটি অনেক সময় খুঁজে পায়না। এর কারণ মুলত শিক্ষা প্রতিষ্ঠানগুলোতে গবেষণার পরিবেশ না থাকা কিংবা আনপ্রোডাক্টিভ খাতে সময়ের অপচয় করা। এছাড়া আগেই যেমনটা বলেছি– শিক্ষার্থীদের মোটিভেশনের অভাব আরেকটি বড় কারণ। অনেক সময় শিক্ষক গবেষণায় আগ্রহী কিন্তু শিক্ষার্থী সিস্টেমের ফাঁক ফোকর ব্যবহার করে দায়সারা কাজ করে পার পেয়ে যেতে চায়।\nগবেষণা পদ্ধতি এই লেখায় গবেষণার বিস্তারিত আলোচনা করবো না। গবেষণার পুরো বৃত্তান্তের স্টেপ বাই স্টেপ বর্ণনা করেছেন রাগিব হাসান তার গবেষণায় হাতেখড়ি বইটিতে। আমি সেখানকার চুম্বক অংশ তুলে দিচ্ছি।\n বইটা ভাগ করা হয়েছে কয়েকটি অংশে। প্রথমে আলোচনা করা হয়েছে গবেষণা কাকে বলে, এর প্রয়োজনীয়তা এবং মূলনীতি নিয়ে। এর পরে আস্তে আস্তে বলা হয়েছে, কীভাবে গবেষণা শুরু করবেন, বিষয় নির্বাচন ও লিটারেচার রিভিউ করবেন। তার পরে ধাপে ধাপে দেখানো হয়েছে, রিসার্চ পেপার পড়া, বোঝা, এবং নিজের গবেষণাপত্র কীভাবে লিখবেন। গবেষণার সমস্যা সমাধানের জন্য নতুন আইডিয়া কীভাবে চিন্তা করবেন ও যাচাই করবেন। এছাড়া গবেষণার ফলাফলকে প্রেজেন্টেশন বা বক্তৃতার মাধ্যমে উপস্থাপন করার নানা কৌশল সম্পর্কে লিখেছি। এবং সবশেষে আলোচনা করেছি গবেষণার অর্থায়ন কীভাবে করবেন, এবং গবেষণার সাথে আনুসঙ্গিক অনেক বিষয় যেমন গবেষকদের অভ্যাস, গবেষণার জন্য সময় জোগাড় করা, এসব কিছু।\n আমি নতুন করে চাকা আবিষ্কার না করে বরং সংক্ষেপে ধাপগুলো তুলে ধরছি। এটি বিশেষ করে যারা আমার সাথে কাজ করতে চান তাদের জন্য অবশ্যপাঠ্য। তাছাড়া নিজেদের গবেষণাতেও এই ধাপগুলো অনুসরণ করা যাবে। হয়তো কাজের ধারা কিছুটা বদলাতে হতে পারে। সেটি নির্ভর করবে কী ধরনের গবেষণা হচ্ছে তার উপর।\nসমস্যা কোথায় পাবেন? সমস্যা অনেক ভাবে পাওয়া যেতে পারে। যারা কোন বিষয়ের অভিজ্ঞ বা অথরিটি তারা খুব সহজেই একটা গবেষণা করার মতো সমস্যা বের করতে পারেন। কিন্তু নতুন গবেষকদের জন্য এটি অনেক কঠিন একটি বিষয়। তাই তাদের জন্য গবেষণা করার মতো সমস্যা খুঁজে পেতে সংশ্লিষ্ট বিষয়ের জার্নাল থেকে আর্টিকেল পড়ার পরামর্শ দিচ্ছি। এটি সবচেয়ে কম সময়ে ভালো একটি সমস্যা খুঁজে পাওয়ার সবচেয়ে সহজ উপায়। আর দ্বিতীয়টি হলো চোখ কান খোলা রাখা এবং নিজের চিন্তা ভাবনা থেকেই সম্ভাব্য সমস্যা বের করা।\nমনে রাখতে হবে সব সমস্যাই গবেষণা করার মতো নয়। অনেক সময় দূরদর্শীতা এবং অভিজ্ঞতার অভাবে একটি কাজ শুরু করে সেটি নানা কারণে শেষ করা হয়ে ওঠে না। প্রথম দিকে তাই অভিজ্ঞ কারো সাথে কাজ করলে কাজটি ভালো ভালোয় শেষ করার সম্ভবনা বাড়ে।\nগবেষণার সমস্যা খুঁজতে গিয়ে আপনি প্রথমেই ব্রড একটা সমস্যা নিয়ে চিন্তা করবেন। তার পর সেখান থেকে ছোট ছোট বা স্পেসিফিক একাধিক সমস্যা বের করুন। সেগুলোকে লিপিবদ্ধ করুন। তারপর সেখান থেকে একটি বা দুটি সমস্যাকে বাছাই করুন। একটি গবেষণায় একটি প্রধান সমস্যাকে লক্ষ্য করে এগুবার পরামর্শ দেবো। এতে করে গবেষণা সেই লক্ষ্যেই স্থির থাকে এবং সকল কর্মকান্ডও ওই লক্ষ্যকে ঘিরে হয় বলে গবেষণাটি ভালো মানের হওয়ার সম্ভবনা থাকে।\nযেমন ধরুন আপনি বাংলাদেশের কলেজ ও বিশ্ববিদ্যালয়ের শিক্ষার্থীদের মধ্যে ক্যানসার সচেতনতা নিয়ে কাজ করবেন বলে স্থির করছেন । ক্যান্সারের অনেক ধরন আছে। এক্ষেত্রে ভালো হবে একটি মাত্র ক্যান্সার (ধরা যাক স্তন ক্যান্সার) নিয়ে কাজ করা। সেই সাথে টার্গেট পপুলেশনে কলেজ শিক্ষার্থীদের না অন্তুর্ভুক্ত করে শুধু বিশ্ববিদ্যালয়ের শিক্ষার্থীদের অন্তর্ভুক্ত করলে আপনার গবেষণাটি আরো ফোকাসড হবে।\nগবেষণার লক্ষ্য ও উদ্দেশ্য নির্ধারণ করা গবেষণার মূল লক্ষ্যই হলো কোন সমস্যাকে তুলে ধরা বা সেটির সমাধানের পথে কী কী করা যায় সে সম্পর্কে রেকমেন্ডেশন দেয়া। সেজন্য গবেষণার মাধ্যমে যে যে প্রশ্নের উত্তর জানা প্রয়োজন সেগুলোকে লিপিবদ্ধ করা দরকার। এতে করে গবেষণাটি সিস্টেমেটিক হবে এবং গবেষণার শেষে লক্ষ্য ও উদ্দেশ্য পূরণ হলো কী না সেটিও পরিমাপ করা যাবে।\nএজন্য গবেষণার প্রশ্ন বা Research Questions (RQs) গুলোকে লিখে রাখতে হবে। অনেকগুলো প্রশ্ন একসাথে লেখা যেতে পারে তবে কয়েকটি স্পেসিফিক প্রশ্নের উত্তর গবেষণায় খোঁজা হবে। এই প্রশ্নগুলোকেই একে একে উত্তর দেয়া হবে কনক্লুসন বা ডিসকাসন সেকশনে।\nলিটারেচার রিভিউ সমস্যা বের করার পর আপনাকে দেখাতে হবে আপনার গবেষণাটি কেন দরকার। অর্থাৎ আপনাকে বোঝাতে হবে আপনার কাজের মোটিভেশন কী? সেজন্য এই সমস্যার উপর ইতোপূর্বে কে কী করেছে এবং তাদের কাজগুলোকে আপনার রিভিউ করতে হবে। লিটারেচার রিভিউ লেখা সহজ নয়। মানে এটিকে খুব সহজ ভাবে নেয়া উচিত নয়। লিটারেচার রিভিউ কেবলমাত্র পূর্বে সম্পাদিত কাজের তালিকা নয় বরং সেই কাজগুলো কীভাবে একটির সাথে আরেকটি সম্পর্কযুক্ত সেটি বুঝে আপনাকে পাঠকউপযোগী করে উপস্থাপন করতে হবে। এরকম উপস্থাপনার উদ্দেশ্য হলো আপনার গবেষণার কনটেক্সট বা প্রাসঙ্গিকতা তৈরী করা। আপনার রিভিউ পড়ে যেন সবাই বুঝতে পারে আপনার অবদান কতটুকু এবং কীভাবে।\n Your work must be put into proper context and argued what you’ve done and why…\n খুব ভালো মানে কাজও কিন্তু ভাল লিটারেচার রিভিউ না থাকার কারণে রিভিউয়াররা বাতিল করে দিতে পারে। এক্ষেত্রে আপনাকেই কাজের নতুনত্ব ও অবদান লেখার মাধ্যমে তুলে ধরতে হবে।\nমেথড অব এনালিসিস বা মেথডলজি এই অংশে মূলত পরিসংখ্যানিক এনালিসিস করা হয়। একজন গবেষক নানা ভাবে তার গবেষণা করতে পারেন। তবে এপিডেমিওলজিকাল এবং সামাজিক-বিজ্ঞানের গবেষণাগুলোকে মোটা দাগে দুই ভাগে ভাগ করা যায়।\n অবজারভেশনাল স্টাডি (Observational study) এক্সপেরিমেন্টাল স্টাডি (Experimental study)  অবজারভেশনাল স্টাডিতে আপনি শুধু অবজার্ভ করবেন বা দেখবেন। সেটি হতে পারে স্টাডি শুরু থেকে ভবিষ্যতের দিকে আপনার স্টাডি সাবজেক্টকে ফলো করা। আবার হতে পারে স্টাডি শুরুর সময় থেকে পিছনের দিকে অরজার্ভ করা। উদাহরণস্বরূপ আপনি দেখতে চাইছেন নেশাদ্রব্য গ্রহণের সাথে স্ট্রোকের সম্পর্ক আছে কিনা বা নেশাদ্রব্য গ্রহণ স্ট্রোকের সম্ভাবনা বাড়িয়ে দেয় কিনা। এজন্য আপনি টার্গেট পপুলেশনের একটি অংশকে আজ থেকে ফলো করা (অবজার্ভ) করা শুরু করলেন এবং আগামী ৫ বছর তাদের অবজার্ভ করবেন। ৫ বছর শেষে আপনি দেখবেন এদের মধ্যে যাদের স্ট্রোক হয়েছে তাদের কেউ কেউ নেশাকারী এবং কেউ কেউ নয়। এভাবে স্টাডি করে দেখা যাবে নেশাদ্রব্য গ্রহণের সাথে স্ট্রোকের এসোসিয়েসন আছে কিনা। এ ধরনের স্টাডিকে বলে প্রসপেকটিভ স্টাডি।\nআবার অন্য ধরনের অবজারভেশনাল স্টাডিতে প্রথমেই তাদেরকে বেছে নেয়া যাদের স্ট্রোক হয়েছে। অর্থাৎ ইভেন্ট যাদের মধ্যে ঘটেছে তাদের বাছাই করে তাদের ইন্টারভিউয়ের মাধ্যমে জানা যে তারা অতীতে কোন নেশাদ্রব্য নিয়মিত গ্রহণ করতো কিনা। এধরনের স্টাডিকে বলে রেট্রোস্পেক্টিভ স্টাডি যা বর্তমানের ইভেন্ট দেখে অতীতকে পর্যবেক্ষণ করা যে ইভেন্টটি ঘটার সাথে অতীতের কার্যকলাপের (নেশাদ্রব্য গ্রহণ) এসোসিয়েশন আছে কিনা।\nকমন একটি অবজারভেশনাল স্টাডি হলো ক্রস-সেকসনাল স্টাডি। এরকম স্টাডি পরিচালনা করা হয় একটি পপুলেশনের বৈশিষ্ট্যগুলোর স্ন্যাপশট দেখার জন্য। যেকোন সময়েই এরকম স্টাডি করা যায়। লক্ষ্য রাখতে হবে সময়টি যেন এমন না হয় যে এটি গবেষণার প্রশ্নের সাথে সম্পর্কযুক্ত। ধরুন আপনি জানতে চাইছেন ঢাকা শহরে প্রতিদিন কত সংখ্যক মানুষ বাইরের জেলাগুলো থেকে আসে। সেজন্য আপনাকে একটি টিপিক্যাল দিন বাছাই করতে হবে যেটার সাথে ঢাকা শহরে মানুষ আসার বিশেষ কোন সম্পর্ক না থাকে। যেমন ইজতেমার মওশুমে অনেক মানুষ ঢাকায় আসে। আপনি যদি সেরকম কোন একটি সময়ে গবেষণার জন্য উপাত্ত সংগ্রহ করেন তাহলে আপনি প্রকৃত চিত্র পাবেন না। এক্ষেত্রে আপনার গবেষণার ফল বায়াসড হবে।\nঅবজারভেশনাল স্টাডিতে শুধুই অবজার্ভ করা হয়, কোন ইন্টারভেনশন দেয়া হয়না।\nএক্সপেরিমেন্টাল স্টাডি অনেকটা ফলোআপ বা প্রসপেক্টিভ অবজারভেশনাল স্টাডির মতো। এখানে মূল পার্থক্য হলো এ ধরনের গবেষণায় নতুন ইন্টারভেনশন দেয়া হয় এটা দেখতে যে ইন্টারভেনশনটির কোন এফেক্ট আছে কিনা। ধরা যাক স্ট্রোক কমাতে নতুন একটি ড্রাগ বা লাইফস্টাইলের এফেক্ট আপনি যাচাই করতে চাইছেন। এক্ষেত্রে আপনি দৈব চয়নের মাধ্যমে আপনার গবেষণায় অংশগ্রহণকারিদের একটি অংশকে এই নতুন ড্রাগ বা লাইফস্টাইল দিবেন আর অন্য অংশকে প্লাসিবো দিবেন। প্লাসিবো হলো ঔষধের মতো যেটির আসলে কোন ঔষধি গুন নেই। বিস্তারিত জানতে উইকিতে দেখুন।\nএনালিসিস এই ধাপে স্ট্যাটিসটিক্যাল এনালিসিস করা হবে। ডেটা সংগ্রহের পর সেটিকে ক্লিন করে সামারি রেজাল্ট এবং পরিসংখ্যানের মডেল (যদি দরকার হয়) ব্যবহার করে সিদ্ধান্ত গ্রহণ করা হবে। গবেষণার জন্য নেয়া নমুনা যদি জনগোষ্ঠীর প্রতিনিধিত্বমূলক হয় তাহলে গবেষণার ফলকে সেই টার্গেট পপুলেশনের উপর জেনারেলাইজ করা যাবে অর্থাৎ গবেষণার ফলটি ওই জনগোষ্ঠীর জন্য প্রযোজ্য এমনটি বলা যাবে।\n আর যদি প্রতিনিধিত্বমূলক নমুনা না হয়ে থাকে তাহলে গবেষণার ফলাফল কেবল ওই গবেষণায় অংশগ্রহণকারিদের জন্যই প্রযোজ্য হবে। কোনভাবেই সেটি মূল জনগোষ্ঠীর জন্য সত্যি এমনটি বলা যাবে না। গবেষণার ফল প্রকাশের সময় এই ব্যাপারটি তাই খুব সতর্কতার সাথে লিখতে হবে যাতে কোন ভুল বোঝাবুঝি না নয়। অনেক সময় সংবাদপত্রে গবেষণার ফলকে পুরো জনগোষ্ঠীর ফল হিসেবে দেখিয়ে খবর প্রকাশিত হয় যা সত্যের অপলাপ মাত্র।\n ডিসকাশন কোন গবেষণার এটি হলো সার অংশ। ব্যবহারকারিরা এবং যারা পলিসি তৈরি করেন তাদের কাছে এই সেকশনটি গুরুত্বপূর্ণ। তারা এটিই পড়বেন এবং সে মোতাবেক সিদ্ধান্ত গ্রহণ বা পরিবর্তন করবেন যাতে জনগোষ্ঠীতে পরিবর্তন আসে।\nএজন্য এই অংশটি খুব সতর্কতার সাথে এবং অল্পকথায় লিখতে পারলে ভালো। এই অংশে গবেষণার প্রাপ্ত ফলগুলোকে প্রেজেন্ট করা হয় এবং তা পূর্ববর্তী গবেষণার ফলের সাথে তুলনা করে দেখানো হয়। শুধু নিজের গবেষণার ফল আলোচনা করলেই হবে না, একই ধরনের অন্য গবেষণার ফলের সাথে আপনার গবেষণার ফলের তুলনামুলক আলোচনা করতে হবে। এই অংশে গবেষণার উদ্দেশ্য এবং RQ গুলোকে পুনর্ব্যক্ত করে দেখাতে হয় আপনি গবেষণা শুরুর আগে যা জানতে চেয়েছিলেন সেগুলোর উত্তর পেয়েছেন কী না।\nএই অংশটি আপনার গবেষণাকে পুনরায় জাস্টিফাই করবে। সেটি সম্ভব হবে ভালো করে সেকশনটি উপস্থাপন করার মাধ্যমে। এরকম উপস্থাপনা করতে পারা সহজ নয়। অভিজ্ঞতার মাধ্যমে এটি অর্জন করা যায়। শেখার জন্য ভালো জার্নালের আর্টিকেল থেকে আপনার গবেষণার সাথে মিল আছে সেরকম আর্টিকেলের ডিসকাশন সেকশন পড়ার পরামর্শ দিব। পড়ার মাধ্যমে জানা হবে আর সেটি নিজের গবেষণাপত্রে লেখার মাধ্যমে চর্চা হবে।\nকনক্লুশন বা উপসংহার পরিশেষে উপসংহারে আপনি আপনার গবেষণার ফলাফল সংক্ষেপে আবারো লিখবেন। অনেক জার্নালে কনক্লুশন এবং ডিসকাশন সেকশন দুটি একত্রে লেখা হয়। সেক্ষেত্রে উপসংহারটিকে আপনার ডিসকাশন সেকশনের শেষ প্যারা হিসেবে লিখতে পারেন। এই সেকশনে পলিসি রেকমেন্ডেশন দিতে পারেন। সেই সাথে আপনার কাজের সীমাবদ্ধতাগুলোও তুলে ধরতে পারেন। সবশেষে ভবিষ্যতে আরও কী কী করা যেতে পারে সেগুলোর একটি আউটলাইন দেয়া যেতে পারে। এ থেকে বোঝা যাবে এই গবেষণায় আপনার অবদান কতটুকু এবং আরও কী কী কাজের সুযোগ আছে যা আপনি কিংবা আগ্রহী গবেষকগণ চিন্তা করতে পারেন।\nকাজের ধারা অনেকেই অনেক ভাবে কাজ করতে পারে তবে আমি আমার মতো করে একটি ওয়ার্কফ্লো দিচ্ছি। আমি প্রথম এবং শেষ থেকে শুরু করে আস্তে আস্তে ভিতরের দিকে কাজ করি। লক্ষ্য, উদ্দেশ্য ও লিটারেচার রিভিউ নিয়ে যুগপদ কাজ করি। লক্ষ্য ও উদ্দেশ্য লেখা হয়ে গেলে এবং রিটারেচার রিভিউ শেষ হলে RQ গুলো কী ভাবে উত্তর করবো সে লক্ষ্যে ডিসকাশন সেকশনে কাজ করি। ডিসকাশন পুরো লেখা হয়না কিন্তু টেমপ্লেট তৈরী করা হয় যেখানে এনালিসিস (ধাপ ৪) থেকে প্রাপ্ত তথ্যগুলো দিয়ে পরবর্তীতে সম্পূর্ণ করা হয়।\nতবে এই ওয়ার্কফ্লো নির্ভর করে কী ধরনের গবেষণা হচ্ছে তার উপর। সাধারণত ধাপগুলো এরকম হতে পারে\nসমস্যা \u0026gt; প্রশ্ন \u0026gt; লিটারেচার রিভিউ \u0026gt; ডিসকাশন টেমপ্লেট \u0026gt; এনালিসিস + মেথডলজি \u0026gt; ডিসকাশন \u0026gt; উপসংহার\nকিংবা হতে পারে\nসমস্যা \u0026gt; প্রশ্ন \u0026gt; লিটারেচার রিভিউ \u0026gt; মেথডলজি\u0026gt; ডিসকাশন টেমপ্লেট + এনালিসিস \u0026gt; ডিসকাশন \u0026gt; উপসংহার\nশেষ কথা আশা করি লেখাটি পড়ে আপনার গবেষণা পদ্ধতি সম্পর্কে একটি রিভিউ হলো। আপনি কোন পদ্ধতি অনুসরণ করে সেটি মন্তব্যে জানালে খুশি হবো। সেই সাথে কোন পরামর্শ যদি থাকে সেটাও জানাতে পারেন।।\nপড়ার জন্য ধন্যবাদ।\nকোলাবরেশন চলুক!\nছবির কৃতজ্ঞতা: https://www.besttechie.com\n","href":"/post/collaborative-research-workflow/","title":"গবেষণা পদ্ধতি ও কোলাবরেটিভ কাজের ধারা"},{"content":" ডেটা সায়েন্স এখন হট টপিক। ডেটা সায়েন্টিস্ট-দের জব মার্কেটে অনেক ডিম্যান্ড। বিদেশের মতো বাংলাদেশে ডেটা সায়েন্সের ব্যবহার এখনো সেরকমভাবে শুরু না হলেও ভেতরে ভেতরে তার প্রস্ততি চলছে। মার্কেটের দিকে তাকালেই আমরা সেটি আন্দাজ করতে পারি। বিশেষ করে তরুণ উদ্যোক্তা, ইন্টারনেট-ভিত্তিক ব্যবসা প্রসারের চিন্তাভাবনা, সরকারের সদিচ্ছা এবং তরুণ মন্ত্রী ও উপদেষ্টাদের ডিজিটাল বাংলাদেশ গড়ার প্রচেষ্টায় পজিটিভলি কাজ করা এবং সর্বোপরি ইন্টারনেট ব্যবহারকারিদের এক্সপোনেনশিয়াল বৃদ্ধি অচিরেই আমাদের ব্যবসা, বাণিজ্য, মার্কেটিংকে এমনভাবে বদলে দেবে যা আমরা এই মুহূর্তে অনেকেই বিশ্বাস করতে পারছিনা।\nযে কারণে নিকট ভবিষ্যতে আমাদের অনেক ডেটা সায়েন্টিস্ট দরকার হবে। দেশের চাহিদা মেটাতে আমাদের নিজেদের মধ্যে থেকেই সেই স্থান পুরণ করতে হবে। আমার কাছে অনেকেই প্রশ্ন করে কিভাবে ডেটা সায়েন্টিস্ট হওয়া যায়। আমি কথোপকথনের মাধ্যমে পুরো প্রসেসটার একটা সারাংশ দেয়ার চেষ্টা করেছি। বিস্তারিত জানতে পুরো লেখাটি পড়ার আহবান জানাচ্ছি।\nডেটা সায়েন্টিস্ট হতে চাই ভাল কথা। কিন্তু শুরুতেই বলে নেই ডেটা সায়েন্টিস্ট হতে চাইলেও সবাই শেষ পর্যন্ত ডেটা সায়েন্টিস্ট হতে পারবেন না। এর মূল কারণ হলো সবাই শেষ পর্যন্ত উৎসাহ ধরে রাখতে পারবেন না এবং যতটা পরিশ্রম দরকার হবে ততটা পরিশ্রম করতে পারবে না। একটুও বাড়িয়ে বলছি না। মোটিভেশন ধরে রাখতে পারা অনেকের জন্য সম্ভব হবে না কেননা বাংলাদেশে এখনো জব মার্কটে ডেটা সায়েন্টিস্ট নামে কোন পদ নেই। তবে অচিরেই আসবে বলে আমি অনুমান করি। সে পর্যন্ত যদি মোটিভেশন ধরে রাখতে পারেন তাহলে সম্ভব হতে পারে।\n   :  ডেটা সায়েন্টিস্ট হওয়ার শর্টকাট রাস্তাটা একটু দেখিয়ে দেন    :  ডেটা সায়েন্টিস্ট হওয়ার একটাই শর্টকাট রাস্তা আছে। ইচ্ছাশক্তি আর পরিশ্রম করার মানসিকতা।    :  আমি ডেটা সায়েন্টিস্ট হতে চাই। তিন মাসে কি ডেটা সায়েন্টিস্ট হওয়া সম্ভব?    :  না, সম্ভব না। তবে চেষ্টা আর অধ্যাবসায়ের মাধ্যমে স্বল্প সময়ে কিছু দক্ষতা অর্জন করা সম্ভব যা আপনাকে ডেটা সায়েন্টিস্ট হতে সহায়তা করবে।    :  কিন্তু ইন্টারনেটে তিন মাসের বুটক্যাম্প আছে দেখছি    :  ট্রাই করে দেখেন। ওই তিন মাসে যা করাবে তা তিন বছরের সমান। যারা এই লাইনে অলরেডি কাজ করছে তাদের জন্য এগুলো কাজে দিতে পারে।    :  ডেটা সায়েন্টিস্ট হতে চাই কিন্তু পরিসংখ্যানের কিছুই জানি না    :  ডেটা সায়েন্স-এর ৯৯ ভাগই স্ট্যাটিসটিক্স। বেশীর ভাগ কাজের জন্য পরিসংখ্যানের বেসিক জ্ঞান থাকতে হবে। তবে মডেলিং এবং মেশিন লারনিং এর জন্য এডভান্সড পরিসংখ্যানের জ্ঞান থাকলে ভালো হবে।    :  কম্পিউটার প্রোগ্রামিং জানতে হবে?     :  প্রোগ্রামিং ছাড়া ডেটা সায়েন্সের কাজ করা অনেকটা পরাটা বানানো জানেন না তাই দোকান থেকে পরাটা কিনে খাওয়ার মতো। কোম্পানি আপনাকে হায়ার করবে পরাটা বানানোর জন্য। অতএব পরাটা বানানো জানতে হবে। সাথে ডিম ভাজিও করা লাগবে।ডিম ভাজির ব্যাপারটা বোঝা গেছে? না বুঝলে বলি \u0026ndash; ডেটা সায়েন্টিস্টদের কাজ শুধু প্রথাগত প্রোগ্রামিং বা প্রথাগত পরিসংখ্যানের ব্যবহার নয়। তার চেয়েও একটু বেশী কিছু। যার জন্য লাগবে কৌতূহল আর কমন সেন্স।    :  দুনিয়া সম্পর্কে কোন খবর রাখি না কিন্তু ডেটা সায়েন্টিস্ট হতে চাই    :  ডেটার দুনিয়া সম্পর্কে খবরা-খবর রাখতে হবে। ডেটা সায়েন্স দ্রুত পরিবর্তনশীল একটি বিষয়। এখানে প্রতিনিয়ত নতুন জিনিস যোগ হচ্ছে। তাই বাজারে টিকে থাকতে হলে নিজেকে সবসময় আপডেটেড রাখতে হবে। আজকের ডেটা সায়েন্স কালেকই পুরনো হয়ে যেতে পারে। প্রথাগত শিক্ষা আপনাকে একটা পর্যায়ে নিয়ে যাবে। বাকীটুকু আপনাকেই এগিয়ে নিতে হবে।    :  সব চাই কিন্তু পরিশ্রম করতে ইচ্ছে করে না, খালি ফেইসবুক করতে ইচ্ছে করে ভালো করে ঘুমানোর জন্যেও পরিশ্রম লাগে। আরেকটু ভেবে দেখুন, পরিশ্রম করতে রাজী আছেন কিনা।    :  ঠিক আছে। আর কী লাগবে?    :  আর যা যা লাগবে সে সম্পর্কে এই পোস্ট থেকে একটা ধারণা পাওয়া যাবে।    :  আচ্ছা, আমি রাজী    :  চলুন তাহলে    অল্পকথায়– যাদের ইচ্ছাশক্তি প্রবল, ধৈর্য্য অসীম, কৌতূহল অদম্য, শুধু তাদের জন্য এই ফিল্ড।\nডেটা সায়েন্স ফিল্ডে কাজের ধরন যদি আমরা পর্যালোচনা করি তাহলে দেখতে পাব এখানে ডেটা নিয়ে কাজ করতে হয়। তার অর্থ পরিসংখ্যানের ভালো বুনিয়াদ লাগবে। ডেটা নিয়ে যেহেতু কাজ করতে হয় সেজন্য স্ট্যাটিসটিক্যাল প্রোগ্রামিংও জানা থাকতে হবে। কম্পিউটার সায়েন্স জানা থাকতে হবে এমন নয়, তবে জেনারেল পারপাস প্রোগ্রামিং-এর অভিজ্ঞতা থাকলে দ্রুত অন্য একটি ল্যাংগুয়েজ শেখা সহজ হয়। তাছাড়া অধিকাংশ ক্ষেত্রে কোড অল্প কিছু পরিবর্তন করে নতুন প্রজেক্টে কাজে লাগানো যায়। এতে করে সময় বাঁচে। এটা করার জন্য অন্যের লেখা কোড বোঝার মতো দক্ষতা অর্জন করতে হবে। সেক্ষেত্রে কম্পিউটার সায়েন্সের ব্যাকগ্রাউন্ড অবশ্যই কাজে দেবে। মনে রাখা দরকার যে ডেটা সায়েন্সের বড় অংশই পরিসংখ্যান আর কম্পিউটার প্রোগ্রামিং আর হ্যাকিং স্কিল।\nডেটা সায়েন্টিস্ট হওয়ার ৭টি ধাপ যদি গুগল করেন how to become a data scientist, অনেক সাইট পাবেন যেখানে ধাপগুলো বলা আছে। এদের মধ্যে সবচেয়ে কম্প্রিহেনসিভ তালিকা দিয়েছে ডেটা ক্যাম্প। আমি তাদের মডেলটি আমার মতো করে লিখছি। ইনফোগ্রাফ দেখতে চাইলে সরাসরি তাদের সাইটে দেখা যাবে।\nসংক্ষেপে ৭টি ধাপ নিম্নরূপ।\n১. পরিসংখ্যান, গণিত ও মেশিন লারনিংএর পাঠ\n২. প্রোগ্রামিং শেখা\n৩. ডেটাবেইজ সম্পর্কে ধারণা রাখা\n৪. ডেটা ম্যানিপুলেশন, ক্লিনিং ও ভিজুয়ালাইজেশন\n৫. ছোট ডেটা থেকে বিগ ডেটা নিয়ে কাজ করা শেখা\n৬. ছোট ছোট প্রজেক্টের মাধ্যমে বাস্তব কাজের অভিজ্ঞতা অর্জন করা\n৭. নিজেকে আপডেটেড রাখা এবং ডেটা সায়েন্স কমিউনিটিতে যুক্ত থাকা\nবিস্তারিত দিচ্ছি।\n১. পরিসংখ্যান, গণিত ও মেশিন লারনিংএর পাঠ আপনি পরিসংখ্যানের ছাত্র হলে এই অংশটুকু স্কিপ করতে পারেন। যদি পুরানো টপিকগুলো ঝালাই করার দরকার হয় তাহলে নিচের সূত্রগুলো রিভিউ করে নিতে পারেন।\nপরিসংখ্যানের প্রাথমিক পাঠের জন্য ইউডাসিটির এই কোর্সটি দেখা যাবে। বাংলায় পরিসংখ্যানের একেবারে প্রাথমিক লেভেলের এই পাঠ নিতে পারেন। পরিসংখ্যানের প্রাথমিক ধারণা এবং রিগ্রশনের ধারণা নিতে হবে। তারপর মেশিন লারনিং-এ যেতে হবে। মেশিন লারনিংএর অনেকগুলো কোর্স অনলাইনে আছে। ফ্রি। তাদের মধ্যে স্ট্যানফোর্ডের এই কোর্সটি দিয়ে শুরু করা যেতে পারে।\nবাংলায় পাইথন দিয়ে মেশিন লারনিং এর একটা ভালো বই পাওয়া যাবে এখানে।\nমেশিন লারনিং শিখতে সবচেয়ে বেশী সময় ব্যয় হবে। ওভারল ধারণা নিতে কমপক্ষে ৩ মাস সময় ব্যয় করতে হবে। কারো কারো আরে বেশী সময় লাগতে পারে।\n২. প্রোগ্রামিং মূলত স্ট্যাটিসটিক্যাল প্রোগ্রামিং জানতে হবে। এর জন্য R বা SAS বা Python এর যে কোনটি কিংবা একাধিক ল্যাঙ্গুয়েজ সম্পর্কে জ্ঞান নিতে হবে। যারা ইতোমধ্যেই পরিসংখ্যান শিখেছেন এবং R বা SAS এর সাথে পরিচিত তারা এগুলো রিভিউ করে নিবেন। আর নতুন ল্যাঙ্গুয়েজ শিখতে চাইলে পাইথন শেখার পরামর্শ দিবো।\nR শেখার অসংখ্য সাইট আছে। যেটা ভালো লাগে সেটা দিয়ে শিখে নিন। ট্রাই-আর নামে একটা সাইট আছে সেটা কোডস্কুল পরিচালনা করে। ওদের লিংক http://tryr.codeschool.com/\nPython শেখার জন্য সেরকম অনেক সাইট আছে। গুগলের একটা সাইট হল https://developers.google.com/edu/python/\nSAS শেখার জন্য ওদের সাইটে কিছু ভিডিও আছে। আর বাংলায় স্যাস-এর একটা কোর্স শিক্ষক ডট কম সাইটে আছে।\nব্যক্তিগতভাবে আমি ওপেন সোর্স এবং ফ্রি সফটওয়্যার পছন্দ করি। তবে কমার্শিয়াল সফটওয়্যারের মধ্যে অন্যতম হল স্যাস। আমেরিকায় হেল্থকেয়ার এবং ফাইন্যানশিয়াল অর্গানাইজেশনে স্যাস ব্যবহার করে। আমার কাছ স্ট্যাকচারড ডেটার ম্যানেজমেন্ট এবং প্রসেসিং এর জন্য স্যাস পছন্দ। আর মডেলিং এর জন্য R পছন্দের।\n৩. ডেটাবেইজ সম্পর্কে ধারণা রাখা ডেটা সায়েন্টিস্টদের কাজের প্রথম ধাপ হলো ডেটাবেইজ থেকে ডেটাকে কোয়েরি করে এনে তারপর কাজ করা। ডেটাবেইজে ম্যাসিভ এমাউন্ট অব ডেটা স্টোর করা থাকে। কোন একটি নির্দিষ্ট বিজনেজ কোশ্চেন উত্তর করতে সব ডেটার দরকার হয়না। শুধু দরকারি ভ্যারিয়েবলগুলোকে নিয়ে মূল ডেটার একটা সাবসেট নিয়ে কাজ করা হয়। সেজন্যই কোয়েরি ল্যাংগুয়েজ জানতে হয়।\nSQL হলো structured query language. এটি আমার মতে দুনিয়ার সবচেয়ে সহজ ল্যাংগুয়েজ। খুবই সহজ। যে কেউই এর লজিকটি একবার বুঝে উঠলে এই ল্যাংগুয়েজ নিয়ে কাজ করা তার জন্য একদম পানির মতো। আপনাকে মাস্টার হতে হবে না। ধারণা থাকলেই কাজ চালাতে পারবেন। তবে এফিশিয়েন্ট কোয়েরি কিভাবে লিখতে হয় সেটার জন্য একটু বেশী করে পড়াশুনা করতে হবে যেটি দরকার মত করে নিতে হবে।\nSQL কে সিকুয়েল বলে। সম্ভবত দ্রুত বলার জন্য এভাবে বলা হয়। তবে এসকিউএল বললেও সেটা ভুল বলা হবে না।\nসিকুয়েল শেখার অনেক সাইটের মধ্যে http://www.sqlcourse.com/ দেখতে পারেন।\n৪. ডেটা ম্যানিপুলেশন, ক্লিনিং ও ভিজুয়ালাইজেশন ডেটা কোয়েরি করার পর সেটাকে সাইজ করতে হবে। এটাকে বলে ডেটা প্রিপারেশন বা ক্লিনিং। কিভাবে ক্লিন করতে হবে সেটা নির্ভর করবে কী প্রশ্নের উত্তর খোঁজা হচ্ছে তার উপর। আগে থেকে এসব স্থির করা থাকলে ডেটা ক্লিনিং এ সময় কম নষ্ট হয়। আমার অভিজ্ঞতার আলোকে দেখেছি ডেটা ক্লিনিং এর কোন নির্দিষ্ট নিয়ম বা প্রথা নেই। এটি পুরোপুরি অভিজ্ঞতানির্ভর এবং প্রজেক্ট নির্ভর। নির্দিষ্ট একটি প্রজেক্টের জন্য ধাপগুলো আপনাকেই বের করতে হবে।\nডেটা ক্লিনিং কে আবার ডেটা মানজিং (data munging) ও বলে। বিশেষ করে ডেটা সায়েন্স ফিল্ডের লোকজন এই শব্দ ব্যবহার করে। পরিসংখ্যানবিদরা হয়তো এই শব্দের সাথে পরিচিত নন।\nR দিয়ে ডেটা ক্লিনিং এর জন্য দুইটা জনপ্রিয় প্যাকেজ আছে। সেগুলো হলো dplyr এবং data.table\nঅনলাইনে এদের টিউটোরিয়াল পাওয়া যায়। তবে সবচেয়ে ভালো হয় এগুলো নিয়ে নিজে নাড়াচাড়া করে শিখে নেয়া। উপরের লিংক থেকে প্যাকেজগুলোর ভিনিয়েট থেকেও কাজ শুরু করার মতো তথ্য পাওয়া যাবে।\nডেটা ভিজুয়ালাইজেশনের জন্য ggviz প্যাকেজ আছে। আর কমার্শিয়াল সফটওয়্যারের মধ্যে ট্যাবলো (Tableau) খুবই জনপ্রিয়। এদের ফ্রি ভারশনও আছে সেটাকে বলে কমিউনিটি এডিশন। আমি সবাইকে এই সফটওয়্যার সম্পর্কে ধারণা নেয়ার পরামর্শ দেই। ট্যাবলো একটি অতি জনপ্রিয় সফটওয়্যার যেটি ইন্ডাস্ট্রিতে ব্যাপকভাবে ব্যবহৃত হয়। এটি শেখা থাকলে আপনার রেজুমে অনেক শক্ত হবে।\n৫. ছোট ডেটা থেকে বিগ ডেটা নিয়ে কাজ করা শেখা ডেটা সায়েন্টিস্টদের প্রায়ই অনেক বড় বড় ডেটা নিয়ে কাজ করতে হয়। কত বড় ডেটা হলে সেটাকে বিগ ডেটা বলা যায় তার কোন সংজ্ঞা নেই। তবে যে ডেটা সাধারণ কনজিউমার লেভেলের কম্পিউটারে দিয়ে এনালাইজ করা যায় না সেই ডেটাকে বিগ ডেটা বলা যায়। একটি ৩ গিগাবাইট ডেটা আপনার ল্যাপটপে নিয়ে কাজ করা সহজ হবে না। এমনকি আপনার ১৬ গিগা ড়্যাম থাকলেও। আর ১০ গিগা বা তারচে বড় ডেটা খুবই কমন। সেগুলো সাধারণ কম্পিউটারের মেমরিতেই ফিট করবে না।\nতো বিগ ডেটার জন্য আমাদের অন্যরকম সলুশন দরকার হয়। সহজ করে বলা যায় আপনি যে কোড লিখেছেন সেই কোডটিকে আরো বড় ডেটার উপর চালানোর জন্য অনেক সময় পরিবর্তন করে নিতে হয়। সেটা নির্ভর করে এভেইলেবল সফটওয়্যারের উপর এবং কোন ধরনের টুল ব্যবহার করছেন তার উপর। বিগ ডেটার জন্য হাডুপ (Hadoop) এবং ম্যাপরিডিউস একসময় খুব জনপ্রিয় ছিল। এখন আরো দ্রুত গতির সলুশন এসেছে। সেরকম একটি হলো স্পার্ক (Spark) - যেটি এপাচে\u0026rsquo;র প্রজেক্ট (Apache).\nস্পার্ক ফ্রেমওয়ার্কে R এবং Python দুটো দিয়েই কাজ করা যায়। স্পার্ক এর R API হলো SparkR এবং পাইথন API হলো PySpark. আপনি যেটাতে স্বচ্ছন্দ বোধ করেন সেটি নিয়ে কাজ করবেন। স্পার্ক নিয়ে পরবর্তীতে বিস্তারিত লেখার ইচ্ছে আছে।\nআরেকটি পাওয়ারফুল প্রজেক্ট আছে সেটি হলো H20. ওদের সাইট হলো h20.ai সময় করে দেখে নিতে পারেন। ইউটিউবে অনেক টিউটোরিয়াল আছে।\n৬. ছোট ছোট প্রজেক্টের মাধ্যমে বাস্তব কাজের অভিজ্ঞতা অর্জন করা এ পর্যন্ত যদি পড়ে থাকেন তাহলে বুঝতে পারছেন কত দ্রুত আপনাকে কতকিছু শিখতে হবে। এত কিছু শেখার পর আপনাকে জব মার্কেটে নামতে হবে। নামার আগে আপনাকে একটি পোর্টফোলিও তৈরী করতে হবে যেখানে আপনি কী কী কাজ করতে পারেন তার প্রোটোটাইপ উদাহরণ হিসেবে রাখতে হবে।\nএই ধাপটিতে আমি মেন্টর করার চেষ্টা করবো। আপনি আগ্রহী হলে আমার সাথে যোগাযোগ রাখুন। শিঘ্রই কিছু ছোট প্রজেক্ট প্রকাশ করবো যেখানে আপনি টুলগুলো ব্যবহার করার চর্চা করতে পারবেন।\n৭. নিজেকে আপডেটেড রাখা এবং ডেটা সায়েন্স কমিউনিটিতে যুক্ত থাকা শেষ কথা হলো শেখার কোন শেষ নেই। টেকনলজি দ্রুত পরিবর্তনশীল। সময়ের সাথে তাই আপনাকেও থাকতে হবে আপডেটেড। নিজেকে আপডেটেড রাখার সবচেয়ে সহজ উপায় হলো এসব টুল নিয়ে প্রতিনিয়ত কাজ করা এবং সেটা অন্যকে শেখানো। শেখানোর মাধ্যমে নিজের শিক্ষা পূর্ণ হয়।\nআশা করি আমি আগ্রহী ছাত্র-ছাত্রীদের সাথে পাবো।\nদীর্ঘ পোস্ট পড়ার জন্য অনেক ধন্যবাদ।\n","href":"/post/how-to-become-a-data-scientist/","title":"ডেটা সায়েন্টিস্ট হওয়ার প্রস্ততি"},{"content":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","href":"/post/2015-07-23-r-rmarkdown/","title":"Hello R Markdown"},{"content":" I was asked if we can do the test of equality of two population variances using Stata. Well, I did not have to do it myself ever, but yes, it is possible to do it. Here is an example. I’ve just made-up the data to show the procedures.\nSuppose we have the following data where the variables may represent two independent samples taken from normally distributed populations. And we want to test if the population variances of the two populations are the same. We will use the sample variances to do the testing.\n/* A fictitious data */ input x y 1 2 2 3 2 4 3 5 3 4 4 6 end; To test if the variances are the same, run the following\n. sdtest x = y Variance ratio test ------------------------------------------------------------------------------ Variable | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- x | 6 2.5 .4281744 1.048809 1.399343 3.600657 y | 6 4 .5773503 1.414214 2.515874 5.484126 ---------+-------------------------------------------------------------------- combined | 12 3.25 .4105613 1.422226 2.346361 4.153639 ------------------------------------------------------------------------------ ratio = sd(x) / sd(y) f = 0.5500 Ho: ratio = 1 degrees of freedom = 5, 5 Ha: ratio \u0026lt; 1 Ha: ratio != 1 Ha: ratio \u0026gt; 1 Pr(F \u0026lt; f) = 0.2638 2*Pr(F \u0026lt; f) = 0.5276 Pr(F \u0026gt; f) = 0.7362 There is another way to do this in case if the mean, standard wwwiation and the sample size are available\n/* first, extract the mean and standard wwwiations of the variables */ . summarize // to extract the mean and standard wwwiations of the variables Variable | Obs Mean Std. Dev. Min Max -------------+-------------------------------------------------------- x | 6 2.5 1.048809 1 4 y | 6 4 1.414214 2 6 . sdtesti 6 2.5 1.04 6 4 1.41 Variance ratio test ------------------------------------------------------------------------------ | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- x | 6 2.5 .4245782 1.04 1.408587 3.591413 y | 6 4 .5756301 1.41 2.520296 5.479704 ---------+-------------------------------------------------------------------- combined | 12 3.25 .4091612 1.417376 2.349442 4.150558 ------------------------------------------------------------------------------ ratio = sd(x) / sd(y) f = 0.5440 Ho: ratio = 1 degrees of freedom = 5, 5 Ha: ratio \u0026lt; 1 Ha: ratio != 1 Ha: ratio \u0026gt; 1 Pr(F \u0026lt; f) = 0.2601 2*Pr(F \u0026lt; f) = 0.5202 Pr(F \u0026gt; f) = 0.7399 . Unbalanced Data input grade section 79 1 80 1 65 1 90 1 67 1 77 1 80 1 45 1 86 1 99 2 78 2 36 2 67 2 78 2 81 2 end; . . /* To see how many grades in each section*/ . tab section section | Freq. Percent Cum. ------------+----------------------------------- 1 | 9 60.00 60.00 2 | 6 40.00 100.00 ------------+----------------------------------- Total | 15 100.00 . . /* Doing the variance test */ . sdtest grade, by(section) Variance ratio test ------------------------------------------------------------------------------ Group | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- 1 | 9 74.33333 4.527693 13.58308 63.89246 84.77421 2 | 6 73.16667 8.553427 20.95153 51.17938 95.15395 ---------+-------------------------------------------------------------------- combined | 15 73.86667 4.183717 16.20347 64.89349 82.83985 ------------------------------------------------------------------------------ ratio = sd(1) / sd(2) f = 0.4203 Ho: ratio = 1 degrees of freedom = 8, 5 Ha: ratio \u0026lt; 1 Ha: ratio != 1 Ha: ratio \u0026gt; 1 Pr(F \u0026lt; f) = 0.1322 2*Pr(F \u0026lt; f) = 0.2645 Pr(F \u0026gt; f) = 0.8678 . end of do-file .  Syntax The syntax of the Stata commands can be found in the Stata help file. Run the following commands in your Stata command prompt, and you will see many examples showing the usage of these commands.\nhelp sdtest help sdtesti The syntax for sdtesti for testing the equality of variances for variable1 and variable2 is\n/* for testing variance of two variables */ sdtest variable1 = variable2 /* for testing variance of a single variable */ sdtesti obs . ave stwww // note the dot (.) after obs /* for testing variance of two variables */ sdtesti obs1 ave1 stwww1 obs2 ave2 stwww2 // there is no dot (.) here /* for testing variance of a single variable to some fixed value */ sdtest grade = 2","href":"/post/testing-equality-of-two-population-variances-using-stata/","title":"Testing equality of two population variances using Stata"},{"content":"This is yet another experiment to see how good is the approximation of binomial probability when we use Poisson and normal distributions for scenarios with large n, and p close to zero or one.\nConsider a problem where the random variable \\(X\\) follows a binomial distribution with a known probability of success \\(p\\), and number of trials \\(n\\). If n becomes large, it may not be possible to calculate the probabilities by hand calculation or using a calculator.\nWe can approximate the binomial distribution with a normal distribution or a Poisson distribution.\nAn example The probability that a person will develop an infection even after taking a vaccine that was supposed to prevent the infection is 0.03. In a random sample of 200 people in a community who got the vaccine, what is the probability that six or fewer people will be infected?\nSolution Let \\(X\\) denote the number of persons getting infected. Clearly, \\(X\\) follows a binomial probability distribution with \\(n=200\\) and \\(p = 0.03\\). The exact probability of having six or fewer people getting infected is\n\\[ P(X \\leq 6) = \\sum_{k=0}^{6} \\binom{200}{k} p^k q^{200-k} \\]\nThe probability is 0.6063. We can verify the calculation using R as\nsum(dbinom(0:6, 200, .03)) ## [1] 0.6063152 Or alternatively,\npbinom(6, 200, .03) ## [1] 0.6063152 To avoid such a big calculation by hand, we can approximate the binomial probability using a Poisson distribution or a normal distribution. I will use both and see which one approximates better.\n  Poisson approximation to the binomial distribution To use Poisson approximation to the binomial probabilities, we consider that the random variable \\(X\\) follows a Poisson distribution with rate \\(\\lambda = np = (200)(0.03) = 6.\\) Now, we can calculate the probability of having six or fewer infections as\n\\[ P(X \u0026lt; 6) = \\sum_{k=0}^{6}\\frac{e^{-6} 6^k}{k!} = 0.6063 \\] which turns out to be the same as we obtained with the binomial distribution.\nWe can verify the calculation in R\nppois(6, lambda = 6) ## [1] 0.6063028 Clearly, Poisson approximation is very close to the exact probability.\n Normal approximation to the binomial distribution We can also calculate the probability using normal approximation to the binomial probabilities. Since binomial distribution is for a discrete random variable and normal distribution is for continuous random variable, we have to make continuity correction to approximate a binomial distribution using the normal distribution.\nFor large \\(n\\) and when \\(np \u0026gt; 5\\) and \\(nq \u0026gt; 5,\\) a binomial random variable \\(X\\) with \\(X \\sim Bin(n, p)\\) can be approximated by a normal distribution with mean = \\(np\\) and variance = \\(npq.\\) That is, \\(X \\sim N(6, \\, 5.82).\\)\nTherefore, the probability that there will be six or fewer cases of incidences can be calculated as\n\\[ P(X \\leq 6) = P\\left(z \\leq \\frac{X-6}{\\sqrt{5.82}} \\right). \\] As mentioned earlier, we have to make the continuity correction, and so the above expression will become \\[ \\begin{align*} P(X \\leq 6) \u0026amp;= P\\left(z \\leq \\frac{(X+0.5) - 6}{\\sqrt{5.82}} \\right) \\\\ \u0026amp;= P\\left(z \\leq \\frac{6.5-6}{\\sqrt{5.82}}\\right) \\\\ \u0026amp;= P(z \\leq 0.2072) \\end{align*} \\]\nUsing a standard normal table or using R, we can obtain the probability, which is 0.5821\npnorm(.2072) ## [1] 0.5820732 We note that the approximation is close to the exact probability 0.6063 but the Poisson approximation does much better.\n Simulation To see how the good the approximations are in repeated samples, we generate 1000 random sample of size 200 from a normal distribution with mean = 6 and standard wwwiation = 5.82. The generated data are used to approximate the binomial probability using Poison and normal distributions.\nWe use the following code to generate the figure below.\napprx \u0026lt;- function(n, p, R = 1000, k = 6) { q = 1- p trueval \u0026lt;- pbinom(k, n, p) # true binomial probability prob.zcc \u0026lt;- prob.zncc \u0026lt;- prob.pois \u0026lt;- NULL for (i in 1:R) { x \u0026lt;- rnorm(n, n * p, sqrt(n * p * q)) z.cc \u0026lt;- ((k + .5) - mean(x))/sd(x) # with cont. correction prob.zcc[i] \u0026lt;- pnorm(z.cc) z.ncc \u0026lt;- (k - mean(x))/sd(x) # no cont. correction prob.zncc[i] \u0026lt;- pnorm(z.ncc) y \u0026lt;- rpois(n, n * p) prob.pois[i] \u0026lt;- length(y[y \u0026lt;= k])/n } list(prob.zcc = prob.zcc, prob.zncc = prob.zncc, prob.pois = prob.pois, trueval = trueval) } R \u0026lt;- 1000 set.seed(10) out \u0026lt;- apprx(n = 200, p = .03, k = 6, R = 1000) # windows(6,5) plot(1:R, out$prob.pois, type = \u0026quot;l\u0026quot;, col = \u0026quot;green\u0026quot;, xlab = \u0026quot;Runs\u0026quot;, main = expression(paste(\u0026quot;Simulated Probabilities: \u0026quot;, n==200, \u0026quot;, \u0026quot;, p==0.03, sep=\u0026quot;\u0026quot;)), ylab = \u0026quot;Probability\u0026quot;, ylim = c(.3, .7)) abline(h = out$trueval, col=\u0026quot;red\u0026quot;, lty=2) lines(1:R, out$prob.zcc, lty = 1, col = \u0026quot;purple\u0026quot;) lines(1:R, out$prob.zncc, lty = 1, col = \u0026quot;orange\u0026quot;) legend(\u0026quot;bottomleft\u0026quot;, c(\u0026quot;Poisson\u0026quot;, \u0026quot;Normal (with cc)\u0026quot;, \u0026quot;Normal (w/o cc)\u0026quot;), lty = c(1), col = c(\u0026quot;green\u0026quot;, \u0026quot;purple\u0026quot;, \u0026quot;orange\u0026quot;)) Above figure shows the calculated probabilities for each run of the simulation. The read horizontal line at 0.6 shows the exact probability. The figure shows that the normal approximation, with or without continuity correction, is underestimating the exact probability while Poisson does a better job approximating it for \\(n=200\\) and \\(p=0.03.\\)\nSince this plot does not reveal much due to overlapping points, we draw boxplots for the calculated probabilities for \\(n= 100, 200, 233, 300,\\) and \\(p=0.03.\\)\n# n = 200 set.seed(10) out \u0026lt;- apprx(n = 200, p = .03, k = 6, R = 1000) # windows(6,5) boxplot(out$prob.pois, boxwex = 0.25, at = 1:1 - .25, col = \u0026quot;green\u0026quot;, main = expression(paste(\u0026quot;Approximating Binomial Probability: \u0026quot;, n==200, \u0026quot;, \u0026quot;, p==0.03, sep=\u0026quot;\u0026quot;)), ylab = \u0026quot;Probablity\u0026quot;, ylim = c(out$trueval - 0.2, out$trueval + 0.25)) boxplot(out$prob.zcc, boxwex = 0.25, at = 1:1 + 0, add = T, col = \u0026quot;purple\u0026quot;) boxplot(out$prob.zncc, boxwex = 0.25, at = 1:1 + 0.25, add = T, col = \u0026quot;orange\u0026quot; ) abline(h = out$trueval, col = \u0026quot;red\u0026quot;, lty=2) legend(\u0026quot;topleft\u0026quot;, c(\u0026quot;Poisson\u0026quot;, \u0026quot;Normal (with cc)\u0026quot;, \u0026quot;Normal (w/o cc)\u0026quot;), fill = c(\u0026quot;green\u0026quot;, \u0026quot;purple\u0026quot;, \u0026quot;orange\u0026quot;))  Conclusion To summarize, we see that for \\(n = 200\\) and \\(p = 0.03,\\) Poisson does better than the normal with continuity correction. However, for larger sample sizes, especially when n is close to 300, the normal approximation is as good as the Poisson approximation. It is to be mentioned here that the normal based approximation has always narrower spread than the Poisson based approximation. More importantly, the results are true for this particular case when \\(p=0.03.\\)\n ","href":"/post/poisson-approximation-of-binomial-probabilities/","title":"Poisson approximation of binomial probabilities"},{"content":"","href":"/categories/analytics/","title":"Analytics"},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/categories/blog/","title":"Blog"},{"content":"","href":"/tags/career/","title":"Career"},{"content":"","href":"/categories/career/","title":"Career"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/tags/config/","title":"Configuration"},{"content":"","href":"/tags/data-science/","title":"Data Science"},{"content":"","href":"/authors/enayet/","title":"Enayet"},{"content":"","href":"/tags/git/","title":"Git"},{"content":"","href":"/authors/muniftanjim/","title":"Muniftanjim"},{"content":"","href":"/categories/notes/","title":"Notes"},{"content":"","href":"/tags/og/","title":"Opengraph"},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/tags/plot/","title":"Plot"},{"content":"","href":"/tags/powerbi/","title":"PowerBI"},{"content":"","href":"/tags/python/","title":"Python"},{"content":"","href":"/tags/r/","title":"R"},{"content":"","href":"/categories/r/","title":"R"},{"content":"","href":"/tags/r-markdown/","title":"R Markdown"},{"content":"","href":"/tags/regression/","title":"Regression"},{"content":"","href":"/search/","title":"Search"},{"content":"","href":"/tags/statjobs/","title":"StatJobs"},{"content":"","href":"/tags/","title":"Tags"},{"content":"","href":"/categories/tutorials/","title":"Tutorials"},{"content":"","href":"/tags/%E0%A6%95%E0%A7%87%E0%A6%BE%E0%A6%B2%E0%A6%BE%E0%A6%AC%E0%A6%B0%E0%A7%87%E0%A6%B6%E0%A6%A8/","title":"কোলাবরেশন"},{"content":"","href":"/tags/%E0%A6%97%E0%A6%AC%E0%A7%87%E0%A6%B7%E0%A6%A3%E0%A6%BE/","title":"গবেষণা"},{"content":"","href":"/tags/%E0%A6%A1%E0%A7%87%E0%A6%9F%E0%A6%BE-%E0%A6%B8%E0%A6%BE%E0%A7%9F%E0%A7%87%E0%A6%A8%E0%A7%8D%E0%A6%B8/","title":"ডেটা সায়েন্স"},{"content":"","href":"/tags/%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%B8%E0%A6%82%E0%A6%96%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A8/","title":"পরিসংখ‍্যান"}]
